{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f02eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob as gb\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils import shuffle\n",
    "from skimage.io import imread, imshow\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.applications.resnet50 import ResNet50\n",
    "from tensorflow.keras.layers import Input, Add, Dropout,Dense, Activation, ZeroPadding2D,\\\n",
    "               BatchNormalization, Flatten, Conv2D, GlobalAveragePooling2D, MaxPooling2D, GlobalMaxPooling2D,MaxPool2D\n",
    "from tensorflow.keras.optimizers import SGD, Adam\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67955c2c",
   "metadata": {},
   "source": [
    "## Loading Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e2cd829",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the data path\n",
    "trainpath= ('................/')\n",
    "\n",
    "# get the training classes\n",
    "keys=os.listdir(trainpath)\n",
    "values=range(len(keys))\n",
    "\n",
    "training_classes = dict (zip(keys,values))\n",
    "print('training_classes = ',training_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652aae01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and resizing training data\n",
    "new_size=224    \n",
    "X_train = []\n",
    "y_train = []\n",
    "train_label=[]\n",
    "folder_item_numbers = []\n",
    "\n",
    "for folder in  os.listdir(trainpath ) : \n",
    "    train_label.append(folder)\n",
    "    files = gb.glob(pathname= str( trainpath  + folder + '/*.jpg'))\n",
    "    folder_item_numbers.append(len(files))\n",
    "    for file in files: \n",
    "        orignal_image = cv2.imread(file)\n",
    "        image = cv2.cvtColor(orignal_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = cv2.resize(image , (new_size,new_size))\n",
    "        X_train.append(resized_image)\n",
    "        y_train.append(training_classes[folder])\n",
    "\n",
    "print('--------------------------------------------------')        \n",
    "foldernames=pd.DataFrame({'Folder_name':train_label})\n",
    "itemnumbers=pd.DataFrame({'Traning Image Numbers':folder_item_numbers})\n",
    "informations=pd.concat([foldernames,itemnumbers],axis=1)\n",
    "print(informations)\n",
    "print('--------------------------------------------------')        \n",
    "#check items in X_test\n",
    "print(\"items in X_train is:       \",len(X_train) , \" items\") \n",
    "print(\"items in y_train is:       \",len(y_train) , \" items\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92570f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing training images with labels\n",
    "plt.figure(figsize=(20,20))\n",
    "for n , i in enumerate(list(np.random.randint(0,len(X_train),12))) : \n",
    "    plt.subplot(3,4,n+1)\n",
    "    plt.imshow(X_train[i])   \n",
    "    plt.axis('off')\n",
    "    def ImageClass(n):\n",
    "        for x , y in training_classes.items():\n",
    "            if n == y :\n",
    "                return x\n",
    "    plt.title(ImageClass(y_train[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634a0654",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "img_size=224\n",
    "X_train,y_train = shuffle(X_train, y_train)\n",
    "# Split the training datdset into two groups\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(X_train, y_train, train_size= 0.8)\n",
    "print('Training Samples =:       ',len(x_train) ,'  and the number of labels is     ', len(y_train))\n",
    "print('Validation Samples =:       ',len(x_valid) ,'  and the number of labels is     ', len(y_valid))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c55b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all TRAIN data to array\n",
    "x_train = np.array(x_train) \n",
    "y_train = np.array(y_train)\n",
    "\n",
    "x_valid = np.array(x_valid)\n",
    "y_valid = np.array(y_valid)\n",
    "\n",
    "y_train = to_categorical(y_train,len(train_label))\n",
    "y_valid = to_categorical(y_valid,len(train_label))\n",
    "\n",
    "print(\"x_train shape  :\" ,x_train.shape)\n",
    "print(\"y_train shape :\", y_train.shape)\n",
    "print('-----------------------------------------')\n",
    "print(\"x_valid shape  :\" ,x_valid.shape)\n",
    "print(\"y_valid shape :\", y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de99aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle data\n",
    "x_train,y_train = shuffle(x_train,y_train)\n",
    "x_valid,y_valid = shuffle(x_valid,y_valid)\n",
    "#normalizing data\n",
    "x_train=x_train/255.0\n",
    "x_valid =x_valid/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c150820a",
   "metadata": {},
   "source": [
    "## building the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11ddd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading ResNet50\n",
    "# Loading the pretrained model without the output of the last convolution block \n",
    "base_model = ResNet50(include_top=False, input_shape=(224, 224, 3), weights = 'imagenet')\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = Flatten()(base_model.output)\n",
    "# Add a fully connected layer with 2048 hidden units and ReLU activation\n",
    "x = Dense(2048, activation='relu')(x)\n",
    "# Adding a fully connected layer having len(image_class) neurons which will  give the probability of image \n",
    "predictions = Dense(len(train_label), activation='softmax')(x)\n",
    "\n",
    "base_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# let's visualize layer names and layer indices to see the layers we will freeze:\n",
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1996cdc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "base_model.summary()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0407466d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#define the fine-tuning layers\n",
    "train_layers=[176,171,168,165]\n",
    "\n",
    "for i in train_layers:\n",
    "    print('Layer name is:      ',base_model.layers[i].name)\n",
    "    print('the input:   ',base_model.layers[i].input)\n",
    "    print('the output:  ',base_model.layers[i].output)\n",
    "    print('....................................................................')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6cd74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def  training_opt(filename):\n",
    "    \n",
    "    file_dir='...............'  # save path\n",
    "    filepath = os.path.join(file_dir,filename+'.hdf5')     # Save the model with the same layer name\n",
    "    checkpoint = ModelCheckpoint(filepath=filepath, monitor='val_accuracy', save_best_only=True, verbose=1)   \n",
    "    earlystop=EarlyStopping( monitor=\"val_loss\",  min_delta=0,   patience=15,  mode=\"auto\")\n",
    "    model_callbacks = [checkpoint, earlystop]\n",
    "    return model_callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfe49e8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "optimize=Adam(learning_rate=0.001)\n",
    "epochs=100\n",
    "batch_size=64\n",
    "\n",
    "for i in train_layers:\n",
    "    Layername=base_model.layers[i].name\n",
    "    print('fine_tuning layer name: -----------------------------    ', Layername)\n",
    "    \n",
    "    for layer in base_model.layers[i:-1]:\n",
    "        layer.trainable = True\n",
    "    \n",
    "    ResNet50_model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    ResNet50_model.compile(loss='categorical_crossentropy', optimizer=optimize, metrics=['accuracy']) \n",
    "    history=ResNet50_model.fit(x_train,y_train, validation_data= (x_valid,y_valid), epochs=epochs, batch_size=batch_size, callbacks=training_opt(Layername), verbose=1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8066fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#showing results and model accuracy \n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = range(epochs)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.grid()\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a35224b",
   "metadata": {},
   "source": [
    "## Loading the Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217643ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the path of the data set\n",
    "testpath = ('......................./')\n",
    "\n",
    "keys=os.listdir(testpath)\n",
    "values=range(len(keys))\n",
    "\n",
    "Test_classes = dict (zip(keys,values))\n",
    "print('Test_classes = ',Test_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4784d6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and resizing of test data\n",
    "new_size=224    \n",
    "x_test = []\n",
    "y_test = []\n",
    "test_labels=[]\n",
    "folder_item_numbers = []\n",
    "\n",
    "for folder in  os.listdir(testpath ) : \n",
    "    test_labels.append(folder)\n",
    "    files = gb.glob(pathname= str( testpath  + folder + '/*.jpg'))\n",
    "    folder_item_numbers.append(len(files))\n",
    "    for file in files: \n",
    "        orignal_image = cv2.imread(file)\n",
    "        image = cv2.cvtColor(orignal_image, cv2.COLOR_BGR2RGB)\n",
    "        resized_image = cv2.resize(image , (new_size,new_size))\n",
    "        x_test.append(resized_image)\n",
    "        y_test.append(Test_classes[folder])\n",
    "        \n",
    "print('--------------------------------------------------')        \n",
    "foldernames=pd.DataFrame({'Label_name':test_labels})\n",
    "itemnumbers=pd.DataFrame({'Number of samples':folder_item_numbers})\n",
    "informations=pd.concat([foldernames,itemnumbers],axis=1)\n",
    "print(informations)\n",
    "print('--------------------------------------------------')        \n",
    "#check items in X_test\n",
    "print(\"items in x_test is:       \",len(x_test) , \" items\") \n",
    "print(\"items in y_test is:       \",len(y_test) , \" items\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e113038f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting all test data to array\n",
    "x_test = np.array(x_test)\n",
    "y_test = np.array(y_test)\n",
    "y_test = to_categorical(y_test,len(test_labels))\n",
    "\n",
    "print('-----------------------------------------')\n",
    "print(\"x_test shape  :\" ,x_test.shape)\n",
    "print(\"y_test shape :\", y_test.shape)\n",
    "#shuffle data\n",
    "x_test,y_test = shuffle(x_test,y_test)\n",
    "#normalizing data\n",
    "x_test =x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6032e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "# loading the fine-tuning model\n",
    "model=load_model('..................../conv5_block3_1_conv.hdf5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "241ee276",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model.predict(x_test)\n",
    "# predicted probabilities generated by the model\n",
    "y_prediction = np.argmax(y_test_pred, axis=1)\n",
    "# ground truth labels\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "\n",
    "y_true.shape, y_prediction.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0675fd2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fd9c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_true, y_prediction)\n",
    "cm\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e577865a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "\n",
    "plt.rcParams.update({'font.size': 16})\n",
    "\n",
    "fig, ax = plot_confusion_matrix(conf_mat=cm,  figsize=(8, 8),\n",
    "                                colorbar=False,\n",
    "                                show_absolute=True,\n",
    "                                show_normed=False,\n",
    "                                class_names=test_labels,cmap=\"OrRd\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc72539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_true, y_prediction, target_names=test_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49399416",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute sensitivity and specificity for multi classification \n",
    "\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "res = []\n",
    "for l in list(range(len(test_labels))):\n",
    "    prec,recall,_,_ = precision_recall_fscore_support(np.array(y_true)==l,\n",
    "                                                      np.array(y_prediction)==l,\n",
    "                                                      pos_label=True,average=None)\n",
    "    res.append([l,recall[0],recall[1]])\n",
    "    \n",
    "pd.DataFrame(res,columns = ['class','sensitivity','specificity'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba86c96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#overall sensitivity and specificity\n",
    "df[1:].mean(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b240016c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test.shape, y_test_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89670fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute ROC curve and ROC area for each class\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from itertools import cycle\n",
    "\n",
    "\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "lw=2\n",
    "n_classes=len(test_labels)\n",
    "\n",
    "plt.figure(figsize=(9,9))\n",
    "plt.grid()\n",
    "plt.rcParams['font.size']=14\n",
    "\n",
    "for i in range(n_classes):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_test_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "colors = cycle(['blue', 'red', 'green','orange'])\n",
    "for i, color in zip(range(n_classes), colors):\n",
    "    plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
    "             label='AUC for class {0} ={1:0.2f}' ''.format(test_labels[i], roc_auc[i]))\n",
    "plt.plot([0, 1], [0, 1], 'k--', lw=lw)\n",
    "plt.xlim([-0.05, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate', fontsize = 16)\n",
    "plt.ylabel('True Positive Rate', fontsize = 16)\n",
    "#plt.title('ROC for brain tumor dataset', fontsize = 16)\n",
    "plt.legend(loc=\"lower right\", fontsize = 14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3092d514",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
